{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto 1 - Aprendizaje Automático\n",
    "### Integrantes:\n",
    "- A. Badilla Olivas B80874\n",
    "- Enrique Vilchez Lizano C18477\n",
    "- Brandon Mora Umaña \n",
    "- Joseph Valverde Kong C18100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "# Models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Utils\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "wine_data = pd.read_csv(\"datasets/winequality_red.csv\")\n",
    "wine_data.head()\n",
    "wine_data.corr()\n",
    "\n",
    "# Remove rows with empty data\n",
    "wine_data.dropna(axis=0, subset=[\"quality\"], inplace=True)\n",
    "\n",
    "# Separate data\n",
    "y_wine = wine_data[\"quality\"]\n",
    "X_wine = wine_data.drop(columns=[\"quality\"])\n",
    "X_wine.describe()\n",
    "\n",
    "# Modify quality labels to 1 or 0\n",
    "y_wine = y_wine.apply(lambda x: 1 if x > 6 else 0)\n",
    "y_wine = y_wine.values\n",
    "\n",
    "# Normalize data\n",
    "normalizer = StandardScaler()\n",
    "X_wine_normalized = pd.DataFrame(normalizer.fit_transform(X_wine))\n",
    "X_wine_normalized.columns = X_wine.columns.astype(str)\n",
    "X_wine_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters selection\n",
    "search_space_log = {\n",
    "    \"fit_intercept\": [True, False],  # Add bias constant or not\n",
    "    \"solver\": ['lbfgs', 'liblinear', 'newton-cholesky', 'newton-cg', 'sag', 'saga'],\n",
    "    'max_iter': [1, 5, 10, 30, 50, 100]\n",
    "}\n",
    "\n",
    "log_classifier = LogisticRegression(random_state=1)\n",
    "grid_search_log = GridSearchCV(\n",
    "    estimator=log_classifier,\n",
    "    param_grid=search_space_log,\n",
    "    scoring=[\"accuracy\", \"precision\", \"recall\", \"roc_auc\"],\n",
    "    refit=\"roc_auc\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search_log.fit(X_wine_normalized, y_wine)\n",
    "result = pd.DataFrame(grid_search_log.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", grid_search_log.best_params_)\n",
    "print(\"Best score:\",grid_search_log.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters selection\n",
    "search_space_tree = {\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],  # Loss criteria\n",
    "    \"splitter\": ['best', 'random'], # Type of split for the nodes\n",
    "    \"max_depth\": [1, 5, 10, 30, 50, 100], # Maxiumun tree depth\n",
    "    \"min_samples_split\": [1, 2, 5, 10] # Minimun number of samples needed to split a node\n",
    "}\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier(random_state=1)\n",
    "grid_search_tree = GridSearchCV(\n",
    "    estimator=tree_classifier,\n",
    "    param_grid=search_space_tree,\n",
    "    scoring=[\"accuracy\", \"precision\", \"recall\", \"roc_auc\"],\n",
    "    refit=\"roc_auc\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search_tree.fit(X_wine_normalized, y_wine)\n",
    "results_tree = pd.DataFrame(grid_search_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \",grid_search_tree.best_params_)\n",
    "print(\"Best score :\",grid_search_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_search_space = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"weights\": ['uniform', 'distance'],\n",
    "    \"algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_search_grid = GridSearchCV(\n",
    "    estimator=knn_classifier,\n",
    "    param_grid=knn_search_space,\n",
    "    scoring=[\"accuracy\", \"precision\", \"recall\", \"roc_auc\"],\n",
    "    refit=\"roc_auc\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "knn_search_grid.fit(X_wine_normalized, y_wine)\n",
    "results_knn = pd.DataFrame(knn_search_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", knn_search_grid.best_params_)\n",
    "print(\"Best score :\", knn_search_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters selection\n",
    "search_space_mlp = {\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'], \n",
    "    'solver': ['lbfgs', 'sgd', 'adams'], \n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'warm_start': [True, False], \n",
    "    'early_stopping': [True, False],\n",
    "}\n",
    "# L2, l1 => hacer le model mas, 1. acercar los pesos a 0, l2, obligar pesos a 0\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=1)\n",
    "grid_search_mlp = GridSearchCV(\n",
    "    estimator=mlp_classifier,\n",
    "    param_grid=search_space_mlp,\n",
    "    scoring=[\"accuracy\", \"precision\", \"recall\", \"roc_auc\"],\n",
    "    refit=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_jobs=6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_search_mlp.fit(X_wine_normalized, y_wine)\n",
    "result_mlp = pd.DataFrame(grid_search_mlp.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", grid_search_mlp.best_params_)\n",
    "print(\"Best score :\", grid_search_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "credit_card_data = pd.read_csv(\"datasets/credit_card_approvals.csv\")\n",
    "credit_card_data.head()\n",
    "\n",
    "# Remove empty rows\n",
    "credit_card_data.dropna(axis=0, subset=[\"Approved\"], inplace=True)\n",
    "\n",
    "# Separate data\n",
    "y_credit = credit_card_data[\"Approved\"]\n",
    "X_credit = credit_card_data.drop(columns=[\"Approved\"])\n",
    "\n",
    "# Get categorical and numerical columns\n",
    "cat_cols = X_credit.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = X_credit.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# Normalize numerical values and transformm categorical ones\n",
    "pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", StandardScaler(), num_cols),\n",
    "        (\"categorical\", OrdinalEncoder(), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_credit_normalized = pd.DataFrame(pipeline.fit_transform(X_credit))\n",
    "X_credit_normalized.columns = num_cols + cat_cols\n",
    "X_credit_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
