{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto 1 - Aprendizaje Automático\n",
    "### Integrantes:\n",
    "- A. Badilla Olivas B80874\n",
    "- Enrique Vilchez Lizano C18477\n",
    "- Brandon Mora Umaña \n",
    "- Joseph Valverde Kong C18100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "\n",
    "# Models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing tools\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Model selection tools\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "\n",
    "# Utils\n",
    "from typing import Tuple, List\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_search(\n",
    "    model: object, search_space: dict, X: pd.DataFrame, Y: pd.Series, verbose: int = 1\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Perform grid search to find the best hyperparameters for a given model.\n",
    "\n",
    "    Args:\n",
    "        model (object): The machine learning model from the sci kit learn library to be used for grid search.\n",
    "        search_space (dict): The hyperparameter search space.\n",
    "        X (pd.DataFrame): The input features.\n",
    "        Y (pd.Series): The target variable.\n",
    "        verbose (int, optional): Verbosity level. Default is 1. \n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best score, best parameters, and the results of the grid search.\n",
    "\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=search_space,\n",
    "        scoring=[\"accuracy\", \"precision\", \"recall\", \"roc_auc\"],\n",
    "        refit=\"roc_auc\",\n",
    "        cv=5,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X, Y)\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    return grid_search.best_score_, grid_search.best_params_, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_get_metrics(model: object, X: pd.DataFrame, Y: pd.Series, n_folds: int) -> Tuple[pd.DataFrame, List[List[float]]]:\n",
    "    \"\"\"\n",
    "    Performs cross validation on a model and gets the metrics mean.\n",
    "    \n",
    "    Args:\n",
    "        model (object): The machine learning model from the sci kit learn library to be used for cross validation.\n",
    "        X (pd.DataFrame): The input features.\n",
    "        Y (pd.Series): The target variable.\n",
    "        n_folds (int): Number of folds for cross validation.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, List[List[float]]]: A data frame containing the mean values of accuracies, precisions, recalls, roc_auc_scores, and the confusion matrix.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get cross validation indices\n",
    "    kf = StratifiedKFold(n_splits=n_folds)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    rocs = []\n",
    "    confusion = []\n",
    "    \n",
    "    # Cross validate\n",
    "    for iteration, (train_index, test_index) in enumerate(kf.split(X, Y)):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        # Get metrics\n",
    "        y_predicted = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(Y_test, y_predicted))\n",
    "        precisions.append(precision_score(Y_test, y_predicted))\n",
    "        recalls.append(recall_score(Y_test, y_predicted))\n",
    "        rocs.append(roc_auc_score(Y_test, y_predicted))\n",
    "        if iteration == 0:\n",
    "            confusion = confusion_matrix(Y_test, y_predicted)\n",
    "    \n",
    "    columns = ['Accuracy', 'Precision', 'Recall', 'Roc & Auc']\n",
    "    metrics = [np.mean(accuracies), np.mean(precisions), np.mean(recalls), np.mean(rocs)]\n",
    "    \n",
    "    dataframe = {'Metric': columns, 'Value': metrics}\n",
    "    return pd.DataFrame(dataframe), confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics: pd.DataFrame, title: str = None, color: object = None):\n",
    "    \"\"\"\n",
    "    Plot metrics as a bar plot.\n",
    "\n",
    "    Args:\n",
    "        metrics (pd.DataFrame): Pandas DataFrame with metrics.\n",
    "        title (str, optional): Title for the plot.\n",
    "        colors (object, optional): Colors used for the heat map. Defaults to None.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create the bar plot\n",
    "    \"\"\"\n",
    "    rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if color is not None:\n",
    "        bar_plot = plt.barh(metrics['Metric'], metrics['Value'], color=color(rescale(metrics['Value'])))\n",
    "    else:\n",
    "        bar_plot = plt.barh(metrics['Metric'], metrics['Value'])\n",
    "\n",
    "    # Add a border\n",
    "    for bar in bar_plot:\n",
    "        bar.set_edgecolor(\"black\")\n",
    "        bar.set_linewidth(0.5)\n",
    "\n",
    "    x_offset = 0.01\n",
    "    # Add exact values on the bars\n",
    "    for index, value in enumerate(metrics['Value']):\n",
    "        plt.text(value + x_offset, index, f'{value:.4f}', va='center', ha='left', fontsize=8)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Metric')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title('Model Evaluation Metrics')\n",
    "\n",
    "    # Increase limits\n",
    "    plt.xlim(0, max(metrics['Value']) * 1.15)\n",
    "\n",
    "    # Invert y-axis to have the bars ordered top to bottom\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix: List[List[float]], labels: List[str] = None, title: str = None, colors: object = None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        confusion_matrix (List[List[float]]): Confusion matrix.\n",
    "        labels (List[str], optional): Display labels. Defaults to None (number from 0 to n_classes are chosen).\n",
    "        title (str, optional): Title for the plot. Defaults to None.\n",
    "        colors (object, optional): Colors used for the heat map. Defaults to None.\n",
    "    \"\"\"\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
    "    disp.plot(cmap=colors)\n",
    "            \n",
    "    # Display title\n",
    "    if title is not None:\n",
    "        disp.ax_.set_title(title)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and explore the dataset\n",
    "wine_data = pd.read_csv(\"datasets/winequality_red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with empty data on the label\n",
    "wine_data.dropna(axis=0, subset=[\"quality\"], inplace=True)\n",
    "\n",
    "# Separate data\n",
    "y_wine = wine_data[\"quality\"]\n",
    "X_wine = wine_data.drop(columns=[\"quality\"])\n",
    "X_wine.describe()\n",
    "\n",
    "# Modify quality labels to 1 or 0\n",
    "y_wine = y_wine.apply(lambda x: 1 if x > 6 else 0)\n",
    "y_wine.value_counts()\n",
    "\n",
    "# Scale the data\n",
    "normalizer = StandardScaler()\n",
    "X_wine_normalized = pd.DataFrame(normalizer.fit_transform(X_wine))\n",
    "\n",
    "# After we transform the data, we should put back the column names\n",
    "X_wine_normalized.columns = X_wine.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters selection\n",
    "search_space_log = {\n",
    "    \"fit_intercept\": [True, False],  # Add bias constant or not\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cholesky\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [1, 5, 10, 30, 50, 100],\n",
    "}\n",
    "\n",
    "log_classifier = LogisticRegression(random_state=1)\n",
    "best_log_score, best_log_params, results_log = make_grid_search(\n",
    "    model=log_classifier, search_space=search_space_log, X=X_wine_normalized, Y=y_wine\n",
    ")\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", best_log_params)\n",
    "print(\"Best score:\", best_log_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=1, **best_log_params)\n",
    "metrics, confusion_mat = fit_and_get_metrics(\n",
    "    model=log_classifier, X=X_wine_normalized, Y=y_wine, n_folds=5\n",
    ")\n",
    "plot_metrics(\n",
    "    metrics=metrics,\n",
    "    title='Wine Dataset Logistic Regression Metrics',\n",
    "    color=plt.cm.Blues\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix=confusion_mat,\n",
    "    labels=['Bad Wine', 'Good Wine'],\n",
    "    title='Wine Dataset Logistic Regression Confusion Matrix (First Iteration)',\n",
    "    colors=plt.cm.Blues\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters selection\n",
    "search_space_tree = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],  # Loss criteria\n",
    "    \"splitter\": [\"best\", \"random\"],  # Type of split for the nodes\n",
    "    \"max_depth\": [1, 5, 10, 30, 50, 100],  # Maxiumun tree depth\n",
    "    \"min_samples_split\": [\n",
    "        1,\n",
    "        2,\n",
    "        5,\n",
    "        10,\n",
    "    ],  # Minimun number of samples needed to split a node\n",
    "}\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier(random_state=1)\n",
    "best_tree_score, best_tree_params, tree_results = make_grid_search(\n",
    "    model=tree_classifier, search_space=search_space_tree, X=X_wine_normalized, Y=y_wine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", best_tree_params)\n",
    "print(\"Best score :\", best_tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = DecisionTreeClassifier(random_state=1, **best_tree_params)\n",
    "metrics, confusion_mat = fit_and_get_metrics(\n",
    "    model=tree_classifier, X=X_wine_normalized, Y=y_wine, n_folds=5\n",
    ")\n",
    "plot_metrics(\n",
    "    metrics=metrics,\n",
    "    title='Wine Dataset Decision Tree Metrics',\n",
    "    color=plt.cm.Reds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix=confusion_mat,\n",
    "    labels=['Bad Wine', 'Good Wine'],\n",
    "    title='Wine Dataset Decision Tree Confusion Matrix (First Iteration)',\n",
    "    colors=plt.cm.Reds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_search_space = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"p\": [1, 2],\n",
    "}\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "best_knn_score, best_knn_params, results_knn = make_grid_search(\n",
    "    model=knn_classifier, search_space=knn_search_space, X=X_wine_normalized, Y=y_wine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", best_knn_params)\n",
    "print(\"Best score :\", best_knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(**best_knn_params)\n",
    "metrics, confusion_mat = fit_and_get_metrics(\n",
    "    model=knn_classifier, X=X_wine_normalized, Y=y_wine, n_folds=5\n",
    ")\n",
    "plot_metrics(\n",
    "    metrics=metrics,\n",
    "    title='Wine Dataset KNN Metrics',\n",
    "    color=plt.cm.Greens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix=confusion_mat,\n",
    "    labels=['Bad Wine', 'Good Wine'],\n",
    "    title='Wine Dataset KNN Confusion Matrix (First Iteration)',\n",
    "    colors=plt.cm.Greens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters selection\n",
    "search_space_mlp = {\n",
    "    \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adams\"],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"warm_start\": [True, False],\n",
    "    \"early_stopping\": [True, False],\n",
    "}\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=1)\n",
    "best_mlp_score, best_mlp_params, mlp_results = make_grid_search(\n",
    "    model=mlp_classifier, search_space=search_space_mlp, X=X_wine_normalized, Y=y_wine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned hyperparameters (best parameters): \", best_mlp_params)\n",
    "print(\"Best score :\", best_mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = MLPClassifier(random_state=1, **best_mlp_params)\n",
    "metrics, confusion_mat = fit_and_get_metrics(\n",
    "    model=mlp_classifier, X=X_wine_normalized, Y=y_wine, n_folds=5\n",
    ")\n",
    "plot_metrics(\n",
    "    metrics=metrics,\n",
    "    title='Wine Dataset Neural Network Metrics',\n",
    "    color=plt.cm.Purples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    confusion_matrix=confusion_mat,\n",
    "    labels=['Bad Wine', 'Good Wine'],\n",
    "    title='Wine Dataset Neural Network Confusion Matrix (First Iteration)',\n",
    "    colors=plt.cm.Purples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "credit_card_data = pd.read_csv(\"datasets/credit_card_approvals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "credit_card_data.dropna(axis=0, subset=[\"Approved\"], inplace=True)\n",
    "\n",
    "# Separate data\n",
    "y_credit = credit_card_data[\"Approved\"]\n",
    "X_credit = credit_card_data.drop(columns=[\"Approved\"])\n",
    "\n",
    "# Get categorical and numerical columns\n",
    "cat_cols = X_credit.select_dtypes(include=\"object\").columns.tolist()\n",
    "num_cols = X_credit.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# Normalize numerical values and transformm categorical ones\n",
    "pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", StandardScaler(), num_cols),\n",
    "        (\"categorical\", OrdinalEncoder(), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_credit_normalized = pd.DataFrame(pipeline.fit_transform(X_credit))\n",
    "X_credit_normalized.columns = num_cols + cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
